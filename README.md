# Kafka Connect Cluster Split Test

Тестовый проект для проверки отказоустойчивости распределённого кластера Kafka + Kafka Connect + Debezium при выходе из строя половины узлов. Скрипты позволяют разворачивать кластер с различными конфигурациями репликации и фактором репликации, моделировать отказ половины нод в двух дата-центрах и проверять способность системы к восстановлению и продолжению синхронизации данных.

## Docker Compose

`docker-compose.yml` разворачивает распределённый кластер из двух дата-центров (DC1 и DC2) с общим ZooKeeper ансамблем:

- **Kafka**: 8 брокеров (4 в DC1: kafka1-4, 4 в DC2: kafka5-8), параметры репликации системных топиков настраиваются через переменные окружения
- **Kafka Connect**: 4 воркера (connect1-2 в DC1, connect3-4 в DC2) с Debezium и JDBC драйверами, объединённые в единый кластер через `GROUP_ID: connect-cluster`
- **PostgreSQL**: СУБД с логической репликацией (wal_level=logical) для CDC через Debezium

## Конфигурации тестов

Файлы `.env.rfXmisrY` задают параметры репликации для запуска тестов:
- `rf` — replication factor (фактор репликации)
- `misr` — min in-sync replicas (минимальное количество синхронизированных реплик)

| Файл                     | Описание                                                                                             |
|--------------------------|------------------------------------------------------------------------------------------------------|
| `.env.rf3misr2`          | RF=3, MinISR=2 — базовая конфигурация                                                                |
| `.env.rf4misr2`          | RF=4, MinISR=2                                                                                       |
| `.env.rf5misr2`          | RF=5, MinISR=2                                                                                       |
| `.env.rf6misr2`          | RF=6, MinISR=2 — максимальная репликация                                                             |
| `.env.rf4misr2_rf3misr2` | RF=4 для системных топиков Kafka, RF=3 для топиков данных (Connect), MinISR=2 — раздельные настройки |

Переменные окружения:
- `KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR` — RF для системного топика `__consumer_offsets`
- `KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR` — RF для `__transaction_state`
- `KAFKA_TRANSACTION_STATE_LOG_MIN_ISR` — MinISR для `__transaction_state`
- `KAFKA_MIN_INSYNC_REPLICAS` — MinISR по умолчанию для всех топиков
- `CONNECT_REPLICATION_FACTOR` — RF для топиков данных Connect (offsets, config, status)
- `CONNECT_MIN_INSYNC_REPLICAS` — MinISR для топиков данных Connect

## Тестовый сценарий

Тест проверяет способность кластера продолжать работу при потере половины нод (DC2). Схема данных: PostgreSQL → Debezium (CDC) → Kafka → JDBC Sink → PostgreSQL (целевая база).

**Алгоритм выполнения теста:**

| Этап | Скрипт                                           | Описание                                                |
|------|--------------------------------------------------|---------------------------------------------------------|
| 1    | `source .env.rfXmisrY`                           | Загрузка конфигурации (RF и MinISR)                     |
| 2    | `docker compose up -d`                           | Запуск Kafka кластера (без Connect)                     |
| 3    | `./create-connect-topics.sh`                     | Создание топиков для Kafka Connect                      |
| 4    | `docker compose --profile connect up -d`         | Запуск Kafka Connect воркеров                           |
| 5    | `./wait-connect-ready.sh`                        | Ожидание готовности Connect кластера                    |
| 6    | `./generate-connectors.sh`                       | Генерация конфигураций коннекторов                      |
| 7    | `./deploy-connectors.sh`                         | Развёртывание Debezium и JDBC Sink коннекторов          |
| 8    | `./fill-src-data.sh`                             | Наполнение исходных таблиц (src) данными                |
| 9    | `./check-dst-counts.sh`                          | Проверка копирования данных в целевые таблицы (dst)     |
| 10   | `./stop-dc2-services.sh`                         | Остановка половины кластера (DC2: kafka5-8, connect3-4) |
| 11   | `./fill-src-data.sh`                             | Повторная вставка данных для проверки работоспособности |
| 12   | Анализ логов `docker logs connect1` / `connect2` | Проверка на наличие ошибок в оставшихся воркерах        |

**Цель теста:** подобрать такие комбинации RF и MinISR, при которых остановка половины кластера не приводит к ошибкам в логах Kafka Connect и прерыванию синхронизации данных.

## Результаты тестов

### RF=4, MinISR=2 (с broker.rack)

При конфигурации RF=4, MinISR=2 и включённом `broker.rack` для распределения реплик по дата-центрам:

- **Отказ целого ДЦ (DC2)**: кластер продолжает работу, т.к. в DC1 остаются 2 реплики, что удовлетворяет MinISR=2
- **Отказ половины реплик в каждом ДЦ**: приводит к ошибкам в Kafka Connect, т.к. некоторые партиции теряют более половины реплик и перестают удовлетворять MinISR=2

### RF=6, MinISR=2 (с broker.rack)

При конфигурации RF=6, MinISR=2 и включённом `broker.rack`:

- **Отказ половины реплик в каждом ДЦ**: кластер продолжает работать без ошибок в Kafka Connect
- **Минимум реплик**: RF=6 обеспечивает наличие минимум 3 реплик в каждом ДЦ, при потере половины остаётся 2+ реплик — достаточно для MinISR=2
- **Перебалансировка**: лидеры топиков переизбираются, все партиции остаются доступными

**Рекомендация**: RF=6 с MinISR=2 обеспечивает отказоустойчивость при потере половины реплик в каждом дата-центре (worst-case сценарий). RF=4 достаточно только для отказа целого дата-центра, но не подходит для частичных потерь в обоих ДЦ.

